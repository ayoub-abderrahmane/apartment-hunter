Documentation â€“ ModÃ¨les de RÃ©gression pour la PrÃ©diction du Prix des Maisons

1. Contexte du projet

Ce projet a pour objectif de prÃ©dire le prix dâ€™un bien immobilier Ã  partir de plusieurs caractÃ©ristiques (features) comme :

- la superficie,

- la ville,

- le nombre de piÃ¨ces,

- lâ€™Ã©tat du bien, etc.

Pour cela, plusieurs modÃ¨les de rÃ©gression ont Ã©tÃ© testÃ©s afin de comparer leurs performances et leur capacitÃ© Ã  gÃ©nÃ©raliser correctement sur de nouvelles donnÃ©es.

Les trois modÃ¨les principaux utilisÃ©s sont :

la RÃ©gression LinÃ©aire,

le Random Forest Regressor,

le Gradient Boosting Regressor.

Chaque modÃ¨le a ses avantages, ses limites, et rÃ©pond Ã  un besoin diffÃ©rent (simplicitÃ©, robustesse, performance).

2. La RÃ©gression LinÃ©aire
Description gÃ©nÃ©rale

La rÃ©gression linÃ©aire est le modÃ¨le le plus simple et le plus utilisÃ© en rÃ©gression. Elle cherche Ã  Ã©tablir une relation mathÃ©matique entre les variables dâ€™entrÃ©e (features) et la variable cible (le prix).

Elle repose sur une formule du type :

Prix = aâ‚Ã—Feature1 + aâ‚‚Ã—Feature2 + aâ‚ƒÃ—Feature3 + b

Chaque coefficient reprÃ©sente lâ€™influence dâ€™une variable sur le prix.

âš™ï¸ Fonctionnement

Le modÃ¨le ajuste automatiquement les coefficients pour minimiser lâ€™erreur entre les prix prÃ©dits et les prix rÃ©els.
Lâ€™apprentissage se fait en trouvant la meilleure droite (ou hyperplan en plusieurs dimensions) qui passe au plus prÃ¨s des donnÃ©es.

âœ… Avantages

Simple et rapide Ã  entraÃ®ner

Facile Ã  interprÃ©ter

TrÃ¨s bon modÃ¨le de rÃ©fÃ©rence (baseline)

Faible coÃ»t de calcul

âŒ InconvÃ©nients

GÃ¨re mal les relations complexes

Sensible aux valeurs aberrantes (outliers)

Peu performante si la relation entre les variables nâ€™est pas linÃ©aire

ğŸ¯ RÃ´le dans le projet

Elle sert de point de comparaison de base pour juger lâ€™apport des modÃ¨les plus avancÃ©s.

3. Random Forest Regressor
Description gÃ©nÃ©rale

Le Random Forest est un modÃ¨le basÃ© sur un ensemble dâ€™arbres de dÃ©cision. Au lieu de faire une seule prÃ©diction, il en fait des centaines, puis calcule la moyenne.

Câ€™est un modÃ¨le trÃ¨s utilisÃ© dans lâ€™immobilier car il gÃ¨re bien :

les donnÃ©es bruitÃ©es,

les relations non linÃ©aires,

les interactions entre variables.

âš™ï¸ Fonctionnement

Plusieurs arbres de dÃ©cision sont construits Ã  partir de sous-Ã©chantillons du jeu de donnÃ©es.

Chaque arbre fait une prÃ©diction de prix.

Le modÃ¨le final prend la moyenne de toutes les prÃ©dictions.

Ce principe permet de rÃ©duire le risque de surapprentissage (overfitting).

âœ… Avantages

TrÃ¨s bonne prÃ©cision

Robuste aux erreurs et au bruit

Capable de gÃ©rer des relations complexes

Peu sensible aux valeurs aberrantes

âŒ InconvÃ©nients

Plus lent Ã  entraÃ®ner

Moins interprÃ©table quâ€™une rÃ©gression linÃ©aire

ModÃ¨le plus lourd

ğŸ¯ RÃ´le dans le projet

Câ€™est le modÃ¨le intermÃ©diaire, souvent trÃ¨s performant sans rÃ©glages complexes.

4. Gradient Boosting Regressor
Description gÃ©nÃ©rale

Le Gradient Boosting est un modÃ¨le basÃ© sur un apprentissage progressif par correction des erreurs.
Contrairement au Random Forest oÃ¹ les arbres sont indÃ©pendants, ici chaque arbre apprend Ã  corriger les erreurs du prÃ©cÃ©dent.

On retrouve ce principe dans des bibliothÃ¨ques trÃ¨s connues comme :

XGBoost,

LightGBM,

CatBoost.

âš™ï¸ Fonctionnement

Un premier modÃ¨le fait une prÃ©diction grossiÃ¨re.

Un second modÃ¨le apprend uniquement Ã  prÃ©dire les erreurs du premier.

Le processus se rÃ©pÃ¨te sur plusieurs itÃ©rations.

Les prÃ©dictions sont additionnÃ©es pour produire le rÃ©sultat final.

Cela permet dâ€™obtenir un modÃ¨le trÃ¨s prÃ©cis et trÃ¨s puissant.

âœ… Avantages

Excellente prÃ©cision

TrÃ¨s bon pour les donnÃ©es complexes

TrÃ¨s utilisÃ© en compÃ©tition et en industrie

GÃ¨re bien les non-linÃ©aritÃ©s

âŒ InconvÃ©nients

Plus long Ã  entraÃ®ner

Plus compliquÃ© Ã  rÃ©gler

Risque dâ€™overfitting si mal paramÃ©trÃ©

Peu interprÃ©table

RÃ´le dans le projet

Câ€™est le modÃ¨le final de performance, utilisÃ© pour obtenir les meilleurs rÃ©sultats possibles.

5. Comparaison des modÃ¨les

ModÃ¨le	            SimplicitÃ©	PrÃ©cision	  InterprÃ©tabilitÃ©	Temps d'entraÃ®nement
RÃ©gression LinÃ©aire	âœ…âœ…âœ…    â­â­	      âœ…âœ…âœ…	         TrÃ¨s rapide
Random Forest	    âœ…âœ…	     â­â­â­â­	âœ…                 Moyen
Gradient Boosting	âœ…	      â­â­â­â­â­	âŒ                 Plus long

6. Ã‰valuation des performances

Les modÃ¨les sont Ã©valuÃ©s Ã  lâ€™aide des mÃ©triques suivantes :

MAE (Mean Absolute Error)

RMSE (Root Mean Squared Error)

RÂ² (Coefficient de dÃ©termination)

Cela permet de comparer objectivement les performances et de choisir le modÃ¨le le plus adaptÃ©.

7. Conclusion

Dans ce projet :

La rÃ©gression linÃ©aire sert de rÃ©fÃ©rence simple.

Le Random Forest apporte robustesse et prÃ©cision.

Le Gradient Boosting permet dâ€™atteindre les meilleures performances.

Ce trio offre un bon Ã©quilibre entre comprÃ©hension du modÃ¨le et puissance prÃ©dictive.